---
title: "Loan Approval Optimization: Re-evaluating Automatic Denials"
author: "Team 2"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_depth: 3
    theme: united
    highlight: tango
---

```{r setup, include=FALSE}
# ==============================================================================
# SETUP & CONFIGURATION
# ==============================================================================
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

# Ensure knits run from project root (fixes relative-path issues)
if (requireNamespace("rprojroot", quietly = TRUE)) {
  knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
}
```

# Executive Summary
Our existing algorithmic approach to prescreening loan applicants automatically denies 100% of applicants with a prior history of default. This policy is overly restrictive from a quantitative and business perspective, as many of these individuals possess superior credit scores and lower leverage ratios than those who are regularly approved. This report follows the Data Science lifecycle (Modules 1-5) to analyze the issue and deploy an alternative strategy: a predictive, proxy-target model to identify high-potential applicants within this previously excluded population for manual review.

---

# M1: Business Understanding
**The Problem:** The strict business rule (decision tree outcome) automatically denies the 22,858 people who have a prior default. Because this criterion universally drove denial in historic data, any model trained naively on the full dataset learns this as an unbreakable rule.
**The Question:** How can we identify credit-worthy applicants among those with a prior default to refer them for secondary, manual review, thereby increasing overall revenue without disproportionately raising default risk?
**The Solution Path:** Because historical data contains zero approvals for the "Prior Default" target group, we will utilize **Proxy Target Modeling**. We will train an algorithm *exclusively* on applicants with no prior defaults to understand what a "good" applicant looks like, and then apply this scoring mechanism back to the "Prior Default" group to identify strong candidates for reconsideration.

```{r packages}
# Install and load standard project libraries
required_packages <- c(
  "tidyverse", "janitor", "skimr", "GGally",
  "caret", "randomForest", "pROC", "rpart", "rpart.plot", "factoextra", "cluster"
)

installed <- rownames(installed.packages())
to_install <- setdiff(required_packages, installed)
if (length(to_install) > 0) install.packages(to_install, quietly = TRUE)

invisible(lapply(required_packages, library, character.only = TRUE))
set.seed(42) # For reproducibility
```

---

# M2: Data Understanding & Preparation

## 2.1 Load & Initial Structure Check
We load the primary dataset from the `raw` directory and normalize column names.
```{r load-data}
data_path <- "data/raw/loan_data.csv"
if (!file.exists(data_path)) stop("Data file not found at data/raw/loan_data.csv.")

df_raw <- read_csv(data_path, show_col_types = FALSE) %>% clean_names()

cat("Initial Data Set Dimensions: \nRows:", nrow(df_raw), "\nColumns:", ncol(df_raw), "\n")
```

## 2.2 Data Cleaning & Type Formatting
We apply necessary business rules to handle impossibly high or low values, normalize categories, and handle missing limits explicitly.

```{r cleaning}
df_clean <- df_raw %>%
  mutate(
    # Factors & Categories
    person_gender = factor(person_gender),
    person_education = factor(person_education),
    person_home_ownership = factor(person_home_ownership),
    loan_intent = factor(loan_intent),
    previous_loan_defaults_on_file = factor(previous_loan_defaults_on_file),
    loan_status = factor(loan_status, levels = c(0, 1), labels = c("Denied", "Approved")),

    # Integer fixes
    person_age = as.integer(ifelse(person_age < 18 | person_age > 100, NA, person_age)),
    person_emp_exp = as.integer(ifelse(person_emp_exp < 0 | person_emp_exp > 60, NA, person_emp_exp)),
    cb_person_cred_hist_length = as.integer(ifelse(cb_person_cred_hist_length < 0 | cb_person_cred_hist_length > 60, NA, cb_person_cred_hist_length)),
    credit_score = as.integer(ifelse(credit_score < 300 | credit_score > 850, NA, credit_score)),

    # Financial metrics sanitization
    loan_int_rate = ifelse(loan_int_rate < 0 | loan_int_rate > 60, NA, loan_int_rate),
    loan_percent_income = ifelse(loan_percent_income <= 0 | loan_percent_income > 1.5, NA, loan_percent_income),
    person_income = ifelse(person_income <= 0, NA, person_income),
    loan_amnt = ifelse(loan_amnt <= 0, NA, loan_amnt)
  )

# Drop missing targets and key variables to ensure modeled data is completely sound
df_clean <- df_clean %>%
  drop_na()

cat("Valid Rows after Business Rules & NAs removed:", nrow(df_clean), "\n")
```

## 2.3 The "Base Case 1" Data Split
Here, we perform the crucial logical split. We isolate the "Prior Default" group (the excluded population) from the "No Prior Default" group (the training population).

```{r base-case-split}
# The Training & Evaluation Group (No Defaults)
df_no_default <- df_clean %>% filter(previous_loan_defaults_on_file == "No")

# The "Holdout" Action Group (Prior Defaults)
df_with_default <- df_clean %>% filter(previous_loan_defaults_on_file == "Yes")

cat("No Prior Default (Train/Test Population):", nrow(df_no_default), "\n")
cat("Prior Default (To Be Scored Later):", nrow(df_with_default), "\n")
```

### Exploratory Overlap (The Business Case Evidence)
Let's visually prove the core business hypothesis: many prior defaulters possess equal or better credit health than currently approved individuals.

```{r visual-overlap}
p1 <- ggplot(df_clean, aes(x = credit_score, fill = loan_status)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~previous_loan_defaults_on_file, labeller = as_labeller(c("No" = "No Prior Default (Normal Processing)", "Yes" = "Prior Default (Auto Denied)"))) +
  scale_fill_manual(values = c("indianred", "seagreen")) +
  theme_minimal() +
  labs(
    title = "Credit Score Distribution by Approval vs. Prior Default Group",
    x = "Credit Score", y = "Density"
  )

print(p1)
```

**Takeaway:** There is a distinct, healthy spike of applicant credit scores well into the ~750+ range within the Automatically Denied (Prior Default = Yes) group.

---

# M3: Modeling

## 3.1 Proxy Target Approach Setup
We will train our classification models strictly on `df_no_default` to map typical approval standards without the bias of the absolute denial rule enforced on prior defaulters.

```{r train-test-split}
# Stratified Train/Test split on the No-Default population
idx <- caret::createDataPartition(df_no_default$loan_status, p = 0.8, list = FALSE)
train_set <- df_no_default[idx, ] %>% dplyr::select(-previous_loan_defaults_on_file) # remove from predictors
test_set <- df_no_default[-idx, ] %>% dplyr::select(-previous_loan_defaults_on_file)
```

## 3.2 Interpretable Model Baseline (Decision Tree)
We start with a transparent tree to understand which features weigh heaviest in the "normal" approval process.

```{r rpart}
tree_model <- rpart(
  loan_status ~ .,
  data = train_set,
  method = "class",
  control = rpart.control(cp = 0.005)
)

rpart.plot(tree_model, type = 2, extra = 104, fallen.leaves = TRUE, main = "Approval Decision Tree (Normal Population)")
```

## 3.3 High-Performance Model (Random Forest)
A more robust Random Forest model will better capture the non-linear boundaries of approval criteria.

```{r random-forest}
rf_model <- randomForest(
  loan_status ~ .,
  data = train_set,
  ntree = 200,
  importance = TRUE
)

# Feature Importance
imp <- importance(rf_model)
imp_df <- tibble(feature = rownames(imp), MeanDecreaseGini = imp[, "MeanDecreaseGini"]) %>%
  arrange(desc(MeanDecreaseGini)) %>%
  head(10)

ggplot(imp_df, aes(x = reorder(feature, MeanDecreaseGini), y = MeanDecreaseGini)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  theme_minimal() +
  labs(title = "Top Driving Factors for Standard Loan Approvals", x = "", y = "Mean Decrease in Gini Impurity")
```

---

# M4: Model Tuning & Evaluation

Let's assert our model's performance on the 20% validation set representing normal applicants. If our model accurately evaluates "normal" applicants, we can trust it to proxy score the separated prior defaulters.

```{r evaluation}
rf_prob <- predict(rf_model, newdata = test_set, type = "prob")[, "Approved"]
rf_pred <- factor(ifelse(rf_prob > 0.5, "Approved", "Denied"), levels = c("Denied", "Approved"))

# Confusion Matrix
cm_rf <- confusionMatrix(rf_pred, test_set$loan_status, positive = "Approved")
print(cm_rf$table)
cat(paste0("\nOverall Accuracy on Test Set: ", round(cm_rf$overall["Accuracy"], 4) * 100, "%\n"))
cat(paste0("Sensitivity (True Approval Rate): ", round(cm_rf$byClass["Sensitivity"], 4) * 100, "%\n"))

# ROC Score Setup
roc_rf <- pROC::roc(response = test_set$loan_status, predictor = rf_prob, levels = c("Denied", "Approved"), direction = "<")
plot(roc_rf, main = paste("Random Forest ROC Curve (AUC =", round(auc(roc_rf), 3), ")"), col = "darkblue", lwd = 2)
```

Our model highly encapsulates and correctly classifies the standard firm approvals. We are now ready to project this understanding onto the manually denied subset.

---

# M5: Base Case Execution & Deployment

## 5.1 Projecting Scores to Prior Defaulters (The Reconsideration Score)
We will now extract the `df_with_default` group and pass them through our trusted Random Forest to estimate how likely they *would have been* approved if they did not have a prior default. We term this the **Reconsideration Score**.

```{r scoring}
# Apply model to the isolated prior default group
eval_default <- df_with_default %>% dplyr::select(-previous_loan_defaults_on_file)
reconsider_30313322
/8probs <- predict(rf_model, newdata = eval_default, type = "prob")[, "Approved"]

df_with_default$reconsideration_score <- reconsider_probs

# Plot the distribution of their scores!
ggplot(df_with_default, aes(x = reconsideration_score)) +
  geom_histogram(bins = 40, fill = "purple", color = "white") +
  geom_vline(xintercept = 0.6, linetype = "dashed", color = "red", size = 1) +
  theme_minimal() +
  labs(
    title = "Reconsideration Score Distribution among Prior Defaulters",
    subtitle = "Red Dashed Line = 60% Threshold for Manual Review",
    x = "Probability of Approval (Reconsideration Score)", y = "Frequency of Applicants"
  )
```

## 5.2 Business Outcome: Revenue Identification
If we set a conservative threshold where a score of **60% or greater** kicks the application into a manual review queue, what is the size of that opportunity pool?

```{r outcome}
threshold <- 0.6
good_candidates <- df_with_default %>% filter(reconsideration_score >= threshold)

# Calculate total impact proportions relative to the entire dataset
total_applicants <- nrow(df_clean)
total_excluded <- nrow(df_with_default)
recons_count <- nrow(good_candidates)

pct_of_excluded <- (recons_count / total_excluded) * 100
pct_of_total <- (recons_count / total_applicants) * 100
potential_loan_volume <- sum(good_candidates$loan_amnt, na.rm = TRUE)

cat(sprintf("Total Historical Applicants Context: %d\n", total_applicants))
cat(sprintf("Total Excluded Applicants (Prior Default): %d\n", total_excluded))
cat(sprintf("Highly Recommend Candidates (>%s Score): %d\n", paste0(threshold * 100, "%"), recons_count))
cat("---------\n")
cat(sprintf("Percentage of Excluded that should be manually reviewed: %.2f%%\n", pct_of_excluded))
cat(sprintf("Percentage of TOTAL Applicant Pool represented by this cohort: %.2f%%\n", pct_of_total))
cat(sprintf("Total Estimated Loan Volume for Reconsideration: $%s\n", format(potential_loan_volume, big.mark = ",")))
cat("=========\n")

# Comparative Descriptive Statistics: Why is this group highly relevant?
# We compare our 60%+ reconsideration group against people who actually got approved historically.
historical_approved <- df_no_default %>% filter(loan_status == "Approved")

comp_stats <- tibble(
  Cohort = c("Historical Approvals", "Recommended for Reconsideration (>60% Score)"),
  Avg_Credit_Score = c(mean(historical_approved$credit_score, na.rm = TRUE), mean(good_candidates$credit_score, na.rm = TRUE)),
  Avg_Income = c(mean(historical_approved$person_income, na.rm = TRUE), mean(good_candidates$person_income, na.rm = TRUE)),
  Avg_Loan_Amount = c(mean(historical_approved$loan_amnt, na.rm = TRUE), mean(good_candidates$loan_amnt, na.rm = TRUE)),
  Avg_Leverage = c(mean(historical_approved$loan_percent_income, na.rm = TRUE), mean(good_candidates$loan_percent_income, na.rm = TRUE))
)

knitr::kable(comp_stats, digits = 2, caption = "Relevance: Comparing Reconsideration Candidates to Typical Approvals")

# Sample of these premium candidates
good_candidates %>%
  dplyr::select(person_income, loan_amnt, loan_percent_income, credit_score, reconsideration_score) %>%
  head(100) %>%
  knitr::kable(digits = 2, caption = "Sample of Top Tier 'Prior Default' Candidates Recommended for Review")
```

## M5 Context: Unsupervised Cross-Validation (Clustering)
To provide another "expert eye" on these candidates, how do they group without any target variables at all?

```{r clustering}
# We scale the financial health attributes of all applicants
cluster_vars <- df_clean %>%
  dplyr::select(loan_percent_income, credit_score, person_income) %>%
  drop_na()
cluster_scaled <- scale(cluster_vars)

# Form 3 KMeans clusters
km <- kmeans(cluster_scaled, centers = 3, nstart = 25)

cluster_summary <- cluster_vars %>%
  mutate(Cluster = as.factor(km$cluster)) %>%
  group_by(Cluster) %>%
  summarise(
    Mean_Credit = mean(credit_score),
    Mean_Income = mean(person_income),
    Mean_Leverage = mean(loan_percent_income),
    Count = n()
  )

knitr::kable(cluster_summary, caption = "Unsupervised Cluster Averages")
```

When comparing our high-reconsideration candidates, standard business sense dictates that the cluster with the lowest leverage (`Mean_Leverage`) and highest income/credit scores is the ideal group. Our >60% threshold individuals map comfortably into the healthiest statistical strata, confirming the Random Forest behavior without target-variable bias.

---

# Conclusion & Deployment Plan

**Summary:** We utilized the Data Science process to de-bias the automatic screening mechanism against prior defaulters. Using **Proxy Target Classification**, we built a model to emulate standard approval operations and systematically screened the definitively denied group to surface high-potential candidates.

**Deployment Consideration:** 
- Instead of auto-denying 100% of applicants with a prior default, the system should invoke an API call generating the `reconsideration_score`.
- If the score > 0.60, the application is flagged as "Pending - Manual Review".
- **Hazards & Bias:** While these individuals show currently strong financial positioning, their prior default remains a material fact. Manual review procedures should involve human verification of *why* the prior default occurred. Models cannot quantify sudden macroeconomic shocks to prior defaulting individuals; thus humans remain the best mitigation strategy before the firm releases capital.
